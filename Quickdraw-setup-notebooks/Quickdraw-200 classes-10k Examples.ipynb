{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images from the Quick Draw Dataset 20k examples\n",
    "\n",
    "\n",
    "get the data at https://console.cloud.google.com/storage/browser/quickdraw_dataset/full/numpy_bitmap?pli=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.8\n",
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_examples_per_class = 10000\n",
    "\n",
    "#classes = ['airplane','alarm clock','ambulance','angel','ant','anvil','apple','axe','banana','bandage','barn','baseball bat','baseball',\n",
    "#           'basket','basketball','bathtub','beach','bear','beard','bed','bee','belt','bicycle','binoculars','birthday cake','blueberry',\n",
    "#           'book','boomerang','bottlecap','bowtie','bracelet','brain','bread','broom','bulldozer','bus','bus','butterfly','cactus','cake',\n",
    "#           'calculator','calendar','camel','camera','campfire','candle','cannon','canoe','car','carrot','cello','computer',\n",
    "#           'cat','chandelier','clock','cloud','coffee cup','compass','cookie','couch','cow','crab','crayon','crocodile','crown',\n",
    "#           'cup','diamond','dog','dolphin','donut','dragon','dresser','drill','drums','duck','dumbbell','ear','elbow',\n",
    "#           'elephant','envelope','eraser','eye','eyeglasses','face','fan','feather','fence','finger','fire hydrant',\n",
    "#           'fireplace','firetruck','fish','flamingo','flashlight','flip flops','floor lamp','flower','flying saucer',\n",
    "#           'foot','fork']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['aircraft carrier','airplane','alarm clock','ambulance','angel','ant','anvil','apple','axe','banana','bandage',\n",
    "           'barn','baseball bat','baseball','basket','basketball','bathtub','beach','bear','beard','bed','bee','belt',\n",
    "           'bicycle','binoculars','birthday cake','blueberry','book','boomerang','bottlecap','bowtie','bracelet','brain',\n",
    "           'bread','broom','bulldozer','bus','bush','butterfly','cactus','cake','calculator','calendar','camel','camera',\n",
    "           'campfire','candle','cannon','canoe','car','carrot','cat','cello','chandelier','clock','cloud','coffee cup',\n",
    "           'compass','computer','cookie','couch','cow','crab','crayon','crocodile','crown','cup','diamond','dog',\n",
    "           'dolphin','donut','dragon','dresser','drill','drums','duck','dumbbell','ear','elbow','elephant','envelope',\n",
    "           'eraser','eye','eyeglasses','face','fan','feather','fence','finger','fire hydrant','fireplace','firetruck',\n",
    "           'fish','flamingo','flashlight','flip flops','floor lamp','flower','flying saucer','foot','fork','frog',\n",
    "           'frying pan','garden hose','garden','giraffe','goatee','golf club','grapes','grass','guitar','hamburger',\n",
    "           'hammer','hand','harp','hat','headphones','hedgehog','helicopter','helmet','hexagon','hockey puck',\n",
    "           'hockey stick','horse','hospital','hot air balloon','hot dog','hot tub','hourglass','house plant','house',\n",
    "           'hurricane','ice cream','jacket','jail','kangaroo','key','keyboard','knee','knife','ladder','lantern',\n",
    "           'laptop','leaf','leg','light bulb','lighter','lighthouse','lightning','line','lion','lipstick','lobster',\n",
    "           'lollipop','mailbox','map','marker','matches','megaphone','mermaid','microphone','microwave','monkey',\n",
    "           'moon','mosquito','motorbike','mountain','mouse','moustache','mouth','mug','mushroom','nail','necklace',\n",
    "           'nose','ocean','octagon','octopus','onion','oven','owl','paint can','paintbrush','palm tree','panda',\n",
    "           'pants','paper clip','parachute','parrot','passport','peanut','pear','peas','pencil','penguin','piano',\n",
    "           'pickup truck','picture frame','pig','pillow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the image data from scratch\n",
    "\n",
    "Only use if you are downloading the raw data and doing it yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This cell is only if you are loading the data from scratch\n",
    "# get the data \n",
    "quickdraws = [np.load(\"../../data/{}.npy\".format(qdraw))[:num_examples_per_class] for qdraw in classes]\n",
    "\n",
    "# Concat the arrays together\n",
    "x_data = np.concatenate(quickdraws,axis=0)\n",
    "\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('x_data_100_classes_10k.npy',x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this cell to load the premade datasets that I made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.load(\"../x_data_200_classes_10k.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets make some labels for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[1 1 1 ..., 1 1 1]\n",
      "0 1\n"
     ]
    }
   ],
   "source": [
    "labels = [np.full((num_examples_per_class,), classes.index(qdraw)) for qdraw in classes]\n",
    "print(len(labels))\n",
    "print(labels[1])\n",
    "## Concat the arrays together\n",
    "y_data = np.concatenate(labels,axis=0)\n",
    "y_data.shape\n",
    "print(y_data[9999], y_data[10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at the Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_object(obj):\n",
    "    # Reshape 784 array into 28x28 image\n",
    "    image = obj.reshape([28,28])\n",
    "    fig, axes = plt.subplots(1, )\n",
    "    fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "    plt.imshow(image, cmap='gray_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQKT+H+rauZ9HYiJ4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26df7eff5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "show_object(x_data[53000])\n",
    "print(y_data[53000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000000, 784)\n",
      "(2000000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffling function\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data,y_data = unison_shuffled_copies(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basketball\n"
     ]
    }
   ],
   "source": [
    "y_data[0]\n",
    "print(classes[y_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d8008b550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_object(x_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000000, 784)\n",
      "(2000000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#print(x_data[0])\n",
    "print(x_data.shape)\n",
    "x_data_norm = x_data.reshape(x_data.shape[0], 28, 28, 1)\n",
    "x_data_norm = x_data_norm/255\n",
    "print(x_data_norm.shape)\n",
    "#print(x_data_norm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000000,)\n",
      "15\n",
      "(2000000, 200)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(y_data.shape)\n",
    "print(y_data[0])\n",
    "y_data_onehot = keras.utils.to_categorical(y_data, len(classes))\n",
    "print(y_data_onehot.shape)\n",
    "print(y_data_onehot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700000, 28, 28, 1) (300000, 28, 28, 1)\n",
      "(1700000, 200) (300000, 200)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data_norm, y_data_onehot,\n",
    "                                                    test_size=0.15, random_state=0)\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a small sample to just make sure the NN is working/converging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below code always cause memory error in the AWS GPU instance\n",
    "#x_train_small,_,y_train_small,_ = train_test_split(x_train, y_train, \n",
    "#                                                   test_size=0.95, random_state=0)\n",
    "#_,x_test_small,_,y_test_small = train_test_split(x_test, y_test,\n",
    "#                                              test_size=0.05, random_state=0)\n",
    "#print(x_train_small.shape, x_test_small.shape)\n",
    "#print(y_train_small.shape, y_test_small.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and compile the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 9, 9, 64)          18496     \n",
      "_________________________________________________________________\n",
      "maxpool2 (MaxPooling2D)      (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 200)               115400    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 200)               40200     \n",
      "=================================================================\n",
      "Total params: 174,416\n",
      "Trainable params: 174,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_input = 28,28,1\n",
    "n_classes = len(classes)\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "Inp = Input(shape=(n_input))\n",
    "x = Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', name='conv1')(Inp)\n",
    "x = MaxPooling2D(pool_size=3, name='maxpool1')(x)\n",
    "#x = Dropout(0.3)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', name='conv2')(x)\n",
    "x = MaxPooling2D(pool_size=3, name='maxpool2')(x)\n",
    "#x = Dropout(0.3)(x)\n",
    "#x = Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', name='conv3')(x)\n",
    "#x = GlobalAveragePooling2D(name='avgpool1')(x)\n",
    "#x = MaxPooling2D(pool_size=3, name='maxpool3')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(200, activation='relu', name='Dense1')(x)\n",
    "output = Dense(n_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "model = Model(Inp, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='SGD',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model, checkpoint, reduce_lr, early_stopping callbacks are used\n",
    "One epoch takes about 120 seconds on nvidia GTX1070. It reached 71.1% accuracy after 82 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1700000 samples, validate on 300000 samples\n",
      "lr: 0.01\n",
      "Epoch 1/50\n",
      "1699500/1700000 [============================>.] - ETA: 0s - loss: 1.3358 - acc: 0.6688Epoch 00000: val_loss improved from inf to 1.20242, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 116s - loss: 1.3358 - acc: 0.6688 - val_loss: 1.2024 - val_acc: 0.7050\n",
      "lr: 0.01\n",
      "Epoch 2/50\n",
      "1699400/1700000 [============================>.] - ETA: 0s - loss: 1.3330 - acc: 0.6699Epoch 00001: val_loss improved from 1.20242 to 1.19929, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 117s - loss: 1.3331 - acc: 0.6699 - val_loss: 1.1993 - val_acc: 0.7049\n",
      "lr: 0.01\n",
      "Epoch 3/50\n",
      "1699500/1700000 [============================>.] - ETA: 0s - loss: 1.3320 - acc: 0.6698Epoch 00002: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 116s - loss: 1.3320 - acc: 0.6698 - val_loss: 1.2000 - val_acc: 0.7048\n",
      "lr: 0.01\n",
      "Epoch 4/50\n",
      "1699500/1700000 [============================>.] - ETA: 0s - loss: 1.3303 - acc: 0.6700Epoch 00003: val_loss improved from 1.19929 to 1.19721, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 116s - loss: 1.3302 - acc: 0.6700 - val_loss: 1.1972 - val_acc: 0.7057\n",
      "lr: 0.01\n",
      "Epoch 5/50\n",
      "1699300/1700000 [============================>.] - ETA: 0s - loss: 1.3281 - acc: 0.6707Epoch 00004: val_loss improved from 1.19721 to 1.19409, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 116s - loss: 1.3281 - acc: 0.6707 - val_loss: 1.1941 - val_acc: 0.7062\n",
      "lr: 0.01\n",
      "Epoch 6/50\n",
      "1699400/1700000 [============================>.] - ETA: 0s - loss: 1.3267 - acc: 0.6710Epoch 00005: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3267 - acc: 0.6710 - val_loss: 1.1953 - val_acc: 0.7065\n",
      "lr: 0.01\n",
      "Epoch 7/50\n",
      "1699300/1700000 [============================>.] - ETA: 0s - loss: 1.3255 - acc: 0.6713Epoch 00006: val_loss improved from 1.19409 to 1.19067, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3254 - acc: 0.6713 - val_loss: 1.1907 - val_acc: 0.7072\n",
      "lr: 0.01\n",
      "Epoch 8/50\n",
      "1699800/1700000 [============================>.] - ETA: 0s - loss: 1.3239 - acc: 0.6713Epoch 00007: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3239 - acc: 0.6713 - val_loss: 1.1909 - val_acc: 0.7070\n",
      "lr: 0.01\n",
      "Epoch 9/50\n",
      "1699500/1700000 [============================>.] - ETA: 0s - loss: 1.3220 - acc: 0.6721Epoch 00008: val_loss improved from 1.19067 to 1.19031, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3220 - acc: 0.6721 - val_loss: 1.1903 - val_acc: 0.7076\n",
      "lr: 0.01\n",
      "Epoch 10/50\n",
      "1699200/1700000 [============================>.] - ETA: 0s - loss: 1.3215 - acc: 0.6723- ETA: 1s - Epoch 00009: val_loss improved from 1.19031 to 1.18944, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3214 - acc: 0.6723 - val_loss: 1.1894 - val_acc: 0.7077\n",
      "lr: 0.01\n",
      "Epoch 11/50\n",
      "1699500/1700000 [============================>.] - ETA: 0s - loss: 1.3200 - acc: 0.6722Epoch 00010: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3200 - acc: 0.6722 - val_loss: 1.1949 - val_acc: 0.7052\n",
      "lr: 0.01\n",
      "Epoch 12/50\n",
      "1699400/1700000 [============================>.] - ETA: 0s - loss: 1.3188 - acc: 0.6727Epoch 00011: val_loss improved from 1.18944 to 1.18628, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3188 - acc: 0.6727 - val_loss: 1.1863 - val_acc: 0.7088\n",
      "lr: 0.01\n",
      "Epoch 13/50\n",
      "1699300/1700000 [============================>.] - ETA: 0s - loss: 1.3172 - acc: 0.6733Epoch 00012: val_loss improved from 1.18628 to 1.18407, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3172 - acc: 0.6733 - val_loss: 1.1841 - val_acc: 0.7092\n",
      "lr: 0.01\n",
      "Epoch 14/50\n",
      "1699500/1700000 [============================>.] - ETA: 0s - loss: 1.3156 - acc: 0.6733Epoch 00013: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3155 - acc: 0.6733 - val_loss: 1.1858 - val_acc: 0.7077\n",
      "lr: 0.01\n",
      "Epoch 15/50\n",
      "1699600/1700000 [============================>.] - ETA: 0s - loss: 1.3157 - acc: 0.6732Epoch 00014: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3157 - acc: 0.6732 - val_loss: 1.1849 - val_acc: 0.7085\n",
      "lr: 0.01\n",
      "Epoch 16/50\n",
      "1699600/1700000 [============================>.] - ETA: 0s - loss: 1.3141 - acc: 0.6737Epoch 00015: val_loss improved from 1.18407 to 1.18325, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3141 - acc: 0.6737 - val_loss: 1.1832 - val_acc: 0.7085\n",
      "lr: 0.01\n",
      "Epoch 17/50\n",
      "1699400/1700000 [============================>.] - ETA: 0s - loss: 1.3129 - acc: 0.6736Epoch 00016: val_loss improved from 1.18325 to 1.18321, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3129 - acc: 0.6736 - val_loss: 1.1832 - val_acc: 0.7088\n",
      "lr: 0.01\n",
      "Epoch 18/50\n",
      "1699500/1700000 [============================>.] - ETA: 0s - loss: 1.3104 - acc: 0.6744Epoch 00017: val_loss improved from 1.18321 to 1.18007, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3104 - acc: 0.6744 - val_loss: 1.1801 - val_acc: 0.7093\n",
      "lr: 0.01\n",
      "Epoch 19/50\n",
      "1699100/1700000 [============================>.] - ETA: 0s - loss: 1.3100 - acc: 0.6747Epoch 00018: val_loss improved from 1.18007 to 1.17920, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3100 - acc: 0.6747 - val_loss: 1.1792 - val_acc: 0.7098\n",
      "lr: 0.01\n",
      "Epoch 20/50\n",
      "1699200/1700000 [============================>.] - ETA: 0s - loss: 1.3091 - acc: 0.6745Epoch 00019: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3091 - acc: 0.6746 - val_loss: 1.1795 - val_acc: 0.7100\n",
      "lr: 0.01\n",
      "Epoch 21/50\n",
      "1699300/1700000 [============================>.] - ETA: 0s - loss: 1.3082 - acc: 0.6750Epoch 00020: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3082 - acc: 0.6750 - val_loss: 1.1794 - val_acc: 0.7100\n",
      "lr: 0.01\n",
      "Epoch 22/50\n",
      "1699300/1700000 [============================>.] - ETA: 0s - loss: 1.3064 - acc: 0.6755Epoch 00021: val_loss improved from 1.17920 to 1.17839, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3063 - acc: 0.6755 - val_loss: 1.1784 - val_acc: 0.7094\n",
      "lr: 0.01\n",
      "Epoch 23/50\n",
      "1699900/1700000 [============================>.] - ETA: 0s - loss: 1.3053 - acc: 0.6757Epoch 00022: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3053 - acc: 0.6757 - val_loss: 1.1838 - val_acc: 0.7091\n",
      "lr: 0.01\n",
      "Epoch 24/50\n",
      "1699900/1700000 [============================>.] - ETA: 0s - loss: 1.3052 - acc: 0.6756Epoch 00023: val_loss improved from 1.17839 to 1.17834, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3052 - acc: 0.6756 - val_loss: 1.1783 - val_acc: 0.7098\n",
      "lr: 0.01\n",
      "Epoch 25/50\n",
      "1699100/1700000 [============================>.] - ETA: 0s - loss: 1.3028 - acc: 0.6760Epoch 00024: val_loss improved from 1.17834 to 1.17811, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.3028 - acc: 0.6760 - val_loss: 1.1781 - val_acc: 0.7094\n",
      "lr: 0.01\n",
      "Epoch 26/50\n",
      "1699600/1700000 [============================>.] - ETA: 0s - loss: 1.3028 - acc: 0.6762Epoch 00025: val_loss improved from 1.17811 to 1.17430, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 116s - loss: 1.3028 - acc: 0.6762 - val_loss: 1.1743 - val_acc: 0.7108\n",
      "lr: 0.01\n",
      "Epoch 27/50\n",
      "1699600/1700000 [============================>.] - ETA: 0s - loss: 1.3014 - acc: 0.6768Epoch 00026: val_loss improved from 1.17430 to 1.17266, saving model to quickdraw-200class-10k.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700000/1700000 [==============================] - 116s - loss: 1.3014 - acc: 0.6768 - val_loss: 1.1727 - val_acc: 0.7114\n",
      "lr: 0.01\n",
      "Epoch 28/50\n",
      "1699400/1700000 [============================>.] - ETA: 0s - loss: 1.3012 - acc: 0.6766Epoch 00027: val_loss improved from 1.17266 to 1.17075, saving model to quickdraw-200class-10k.h5\n",
      "1700000/1700000 [==============================] - 116s - loss: 1.3012 - acc: 0.6766 - val_loss: 1.1708 - val_acc: 0.7119\n",
      "lr: 0.01\n",
      "Epoch 29/50\n",
      "1699600/1700000 [============================>.] - ETA: 0s - loss: 1.3002 - acc: 0.6765Epoch 00028: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 116s - loss: 1.3002 - acc: 0.6765 - val_loss: 1.1736 - val_acc: 0.7112\n",
      "lr: 0.01\n",
      "Epoch 30/50\n",
      "1699200/1700000 [============================>.] - ETA: 0s - loss: 1.2992 - acc: 0.6772Epoch 00029: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.2992 - acc: 0.6772 - val_loss: 1.1719 - val_acc: 0.7105\n",
      "lr: 0.01\n",
      "Epoch 31/50\n",
      "1699600/1700000 [============================>.] - ETA: 0s - loss: 1.2984 - acc: 0.6768Epoch 00030: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.2984 - acc: 0.6768 - val_loss: 1.1719 - val_acc: 0.7110\n",
      "lr: 0.01\n",
      "Epoch 32/50\n",
      "1699800/1700000 [============================>.] - ETA: 0s - loss: 1.2972 - acc: 0.6772Epoch 00031: val_loss did not improve\n",
      "1700000/1700000 [==============================] - 115s - loss: 1.2972 - acc: 0.6772 - val_loss: 1.1709 - val_acc: 0.7112\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LambdaCallback, EarlyStopping\n",
    "import keras.backend as K\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='quickdraw-200class-10k.h5', verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, min_lr=0.0001)\n",
    "lr_print = LambdaCallback(on_epoch_begin=lambda epoch,logs: print(\"lr:\", K.eval(model.optimizer.lr)))\n",
    "early_stopping = EarlyStopping(monitor='val_loss',min_delta=0,patience=3,verbose=1,mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                   batch_size=100, epochs=50,\n",
    "                   verbose=1, validation_data=(x_test, y_test),\n",
    "                   callbacks=[checkpointer, reduce_lr, lr_print, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plot the training and validation/testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d80050710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_train(hist):\n",
    "    h = hist.history\n",
    "    if 'acc' in h:\n",
    "        meas='acc'\n",
    "        loc='lower right'\n",
    "    else:\n",
    "        meas='loss'\n",
    "        loc='upper right'\n",
    "    plt.plot(hist.history[meas])\n",
    "    plt.plot(hist.history['val_'+meas])\n",
    "    plt.title('model '+meas)\n",
    "    plt.ylabel(meas)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc=loc)\n",
    "    \n",
    "plot_train(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.17087997942\n",
      "Test accuracy: 0.71116\n"
     ]
    }
   ],
   "source": [
    "# Test against x_test and y_test dataset. Top one result.\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If considering the top 5 returned predictions, the accuracy reached 90.0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_n_rate(model, n, x_test, y_test):\n",
    "    # Get the prediction matrix of all the testing data points\n",
    "    predict_prob = model.predict(x_test)\n",
    "    # Get the top n index matrix\n",
    "    top_n = np.argsort(predict_prob)[:, :-n-1:-1]\n",
    "    \n",
    "    found = .0\n",
    "    for i in range(len(top_n)):\n",
    "        curIndex = np.argmax(y_test[i])\n",
    "        if curIndex in top_n[i]:\n",
    "            # Increase 'found' if the index of the test case is found in the top n\n",
    "            found += 1\n",
    "    return found/len(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299680/300000 [============================>.] - ETA: 0s\n",
      "Top 1 accuracy: 0.71116\n",
      "Top 5 accuracy: 0.8997533333333333\n"
     ]
    }
   ],
   "source": [
    "# Subset a small portion of test dataset.\n",
    "print('\\nTop 1 accuracy:', model.evaluate(x_test, y_test)[1])\n",
    "print('Top 5 accuracy:', get_top_n_rate(model, 5, x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victor/anaconda/envs/tfkeras/lib/python3.5/site-packages/keras/models.py:287: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "#model.save('quickdraw-100class-10k.h5')\n",
    "model = keras.models.load_model('quickdraw-100class-10k.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
